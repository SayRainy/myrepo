1. clean and fix the hadoop cluster throughly.
1)delete files recursively under HADOOP_INSTALL_DIR/[logs] [tmp] for each node.
2)delete files recursively under HBASE_INSTALL_DIR/logs for each node.
3)execute cmd 'hdfs namenode -format' in namenode.
4)before starting the cluster, check and unify the NTP of the cluster.
note: make sure that the time difference between datanode and namenode must be less than 30000ms default.

2. WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
1)bug:
/home/hadoop/hadoop-2.6.0/lib/native/libhadoop.so.1.0.0: wrong ELF class: ELFCLASS64 (Possible cause: architecture word width mismatch)
2)ana:
my machine os is Ubuntu14.04 i686 while the native libraries under the hadoop-2.6.0 installed are based on 64bit. 
3)sln:
fisrtly, export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native".
secondly, build the hadoop native library from the hadoop src as the official doc. Besides it, you can just copy from pre-built library in my mobile-disk.
thirdly, link lib*.so to lib*.so.*.0.0 if not.

3. show the hadoop cmd log in bash.
export HADOOP_ROOT_LOGGER=debug,console

4. job failed.
1)log
 INFO mapreduce.Job: Task Id : attempt_1431738106474_0002_m_000001_2, Status : FAILED
Container [pid=9484,containerID=container_1431738106474_0002_01_000007] is running beyond virtual memory limits. Current usage: 205.6 MB of 1 GB physical memory used; 2.1 GB of 2.1 GB virtual memory used. Killing container.
2)sln
       </property>
	       <property>
               <name>yarn.nodemanager.vmem-check-enabled</name>
               <value>false</value>
       </property>
append this entry to yarn-site.xml

5. HMaster shutdown when execute start-hbase.sh cmd
ZooKeeper architecture is 1+x, which means 1 HMaster plus x>=2*n + 1(n is the broken machine number.)
thus the tolerance of the cluter is n. 
e.g.  1+4 cluster only can have 1 brokendown  node or been shutdown.

6. `hadoop jar` cmd failed.
Bug: 
Hadoop jar my_first_mapred_fat.jar  <main_class>
-Dwordcount.case.sensitive=false 
hdfs://namenode:9000/input/wordcount_test_input hdfs://namenode:9000/output/wordcount_test_output 
-skip hdfs://namenode:9000/input/patterns/patterns.txt

Sln:
如果指定<main_class>则无法正确解析通用参数与特定参数。可通过导出该jar包时指定MainClass。
